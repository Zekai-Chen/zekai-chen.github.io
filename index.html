<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Zekai Chen</title>
<meta name="description" content="AI Application Research Engineer at Futurewei Technologies. Master's student in Systems Engineering (Robotics) at Cornell University.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
<link rel="stylesheet" href="assets/style.css">
<meta property="og:title" content="Zekai Chen">
<meta property="og:description" content="AI Application Research Engineer at Futurewei Technologies. Master's student in Systems Engineering (Robotics) at Cornell University.">
<meta property="og:type" content="website">
<meta property="og:url" content="https://zekai-chen.github.io/">
</head>
<body>

<header class="header">
  <div class="container">
    <nav class="nav">
      <a class="brand" href="index.html">Zekai Chen</a>
      <div class="menu">
        <a href="#papers">Papers</a>
        <a href="#blogs">Blogs</a>
      </div>
    </nav>
  </div>
</header>

<main class="container">
  <div class="intro">
    <img src="assets/profile.jpg" alt="Zekai Chen">
    <div class="intro-content">
      <h1>Zekai Chen</h1>
      <p>I am an AI Application Research Engineer. I currently work at <a href="https://www.futurewei.com/" target="_blank">Futurewei IC labs</a> (San Jose, CA), focusing on multimodal research, particularly on physical world understanding in robotic vision, physics consistency in video generation, and developing related benchmarks and datasets. I also work on agent systems to improve workflow efficiency while maintaining corporate compliance and data security.</p>
      
      <p>From 2024 to 2025, I was at <a href="https://nexaai.com/" target="_blank">Nexa AI</a>, where I co-created on-device model benchmarks (latency, memory usage, power consumption) and researched various RAG pipeline benchmarks, and at <a href="https://www.cuprobotics.org/" target="_blank">Cornell Cup Robotics</a>, where I co-created XRP (open-source desktop educational toy robot).</p>
      
      <p>Before that, I was a research assistant at <a href="https://airs.cuhk.edu.cn/" target="_blank">AIRS</a> (Shenzhen, China), where I integrated robots with language models for real-time conversational interaction.</p>
      
      <p>I am skilled in paper reproduction, inference testing, and benchmark design; self-taught Isaac Sim simulation; and have replicated models including π0, OpenVLA, and Rekep. I am proficient in scheduling/benchmarking on V100, A100, RTX 4090/5090; experienced in local deployment, debugging, and training of open-source multimodal models. I am enthusiastic about mastering emerging AI tools to expand my skillset and apply them in practical projects.</p>
      
      <div class="links">
        <a href="assets/ZEKAI_CHEN_CV.pdf" target="_blank">CV</a>
        <a href="https://linkedin.com/in/zekai-chen" target="_blank">LinkedIn</a>
        <a href="https://github.com/Zekai-Chen" target="_blank">GitHub</a>
        <a href="mailto:zc542@cornell.edu">Email</a>
      </div>
    </div>
  </div>

  <div class="section" id="papers">
    <h2>Papers</h2>
    <ul>
      <li><strong>High-Fidelity 4× Neural Reconstruction of Real-time Path Traced Videos</strong> (Co-first Author). ICCV-AIGENS 2025.</li>
      <li><strong>Physics-Consistency Benchmark for Fluid Video Generation</strong> (Producing)</li>
    </ul>
  </div>

  <div class="section" id="blogs">
    <h2>Blogs</h2>
    <p>Producing</p>
  </div>
</main>

<footer class="footer">
  <div class="container">
    © 2025 Zekai Chen · Built with ❤️ at Cornell
  </div>
</footer>

</body>
</html>
