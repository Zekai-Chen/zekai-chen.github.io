<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Zekai Chen</title>
<link rel="icon" href="assets/icons8-wall-e.svg" type="image/svg+xml">
<meta name="description" content="Robotics Research Engineer at Maxinsights. Master's student in Systems Engineering (Robotics) at Cornell University.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&family=Cinzel:wght@400;500;600&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
<link rel="stylesheet" href="assets/style.css">
<meta property="og:title" content="Zekai Chen">
<meta property="og:description" content="Robotics Research Engineer at Maxinsights. Master's student in Systems Engineering (Robotics) at Cornell University.">
<meta property="og:type" content="website">
<meta property="og:url" content="https://zekai-chen.github.io/">
</head>
<body>

<header class="header">
  <div class="container">
    <nav class="nav">
      <a class="brand" href="index.html">Zekai Chen</a>
      <div class="menu">
        <a href="#papers">Papers</a>
        <a href="#blogs">Blogs</a>
      </div>
    </nav>
  </div>
</header>

<main class="container">
  <div class="intro">
    <img src="assets/profile.jpg" alt="Zekai Chen">
    <div class="intro-content">
      <p>I am a Robotics Research Engineer.<br>
      I currently work at <a href="https://www.linkedin.com/company/maxinsights-ai/posts/?feedView=all" target="_blank">Maxinsights</a> (Santa Clara, CA), a data solutions provider supporting teams such as Gemini Robotics and NVIDIA. I am mentored by <a href="https://scholar.google.com/citations?user=726MCb8AAAAJ&hl=en" target="_blank">Dr. Jiankai Sun</a>.<br>
      My research interests center on using robot foundation models to solve real-world, high-impact everyday and workplace manipulation tasks, with a particular focus on achieving breakthroughs from the data and pipeline side.</p>

      <p>Previously at <a href="https://www.futurewei.com/" target="_blank">Futurewei IC Labs</a> (San Jose, CA), I worked on physics-consistent video generation and conducted related benchmark surveys, mentored by <a href="https://scholar.google.com/citations?user=DxIhPKoAAAAJ&hl=en" target="_blank">Dr. Zhiqiang Lao</a> and <a href="https://www.linkedin.com/in/heather-yu-8866675" target="_blank">Dr. Heather Yu</a>. I also contributed to agent systems for workflow automation in collaboration with <a href="https://www.linaro.org/" target="_blank">Linaro</a>.</p>

      <p>At <a href="https://nexaai.com/" target="_blank">Nexa AI</a> (2024-2025), I co-created on-device model benchmarks and RAG pipeline evaluations, and at <a href="https://cornellcuprobotics.com/" target="_blank">Cornell Cup Robotics</a>, where I co-developed XRP (open-source educational robot).</p>

      <p>Before that, I was a research assistant at <a href="https://airs.cuhk.edu.cn/en" target="_blank">AIRS</a> (Shenzhen, China), integrating robots with language models for real-time interaction.</p>

      <p>Passionate about benchmarking models and producing insightful analysis reports. Experienced in cloud computing services (AWS, GCP) and local deployment with V100/A100/RTX GPUs.</p>
      
      <div class="links">
        <a href="assets/ZEKAI_CHEN_CV.pdf" target="_blank"><i></i>CV</a>
        <a href="https://linkedin.com/in/zekai-chen" target="_blank"><i></i>LinkedIn</a>
        <a href="https://github.com/Zekai-Chen" target="_blank"><i></i>GitHub</a>
        <a href="mailto:zc542@cornell.edu"><i></i>zc542 [at] cornell [dot] edu</a>
      </div>
    </div>
  </div>

  <div class="section" id="papers">
    <h2>Papers</h2>
    <ul>
      <li><a href="https://openaccess.thecvf.com/content/ICCV2025W/AIGENS/papers/Lao_High-Fidelity_4x_Neural_Reconstruction_of_Real-time_Path_Traced_Videos_ICCVW_2025_paper.pdf" target="_blank"><strong>High-Fidelity 4× Neural Reconstruction of Real-time Path Traced Videos</strong></a> (Co-first Author). ICCV-AIGENS 2025.</li>
    </ul>
  </div>

  <div class="section" id="blogs">
    <h2>Blogs</h2>
    <ul>
      <li><a href="https://medium.com/@zc542/a-scalable-robot-data-rig-iphone-insta360-for-ego-3d-demonstrations-5de809f21efa" target="_blank">A Scalable Robot Data Rig: iPhone + Insta360 for Ego-3D Demonstrations</a></li>
      <li><a href="https://medium.com/@zc542/beyond-accuracy-a-comprehensive-benchmark-of-rag-and-multimodal-retrieval-models-c121635701a4" target="_blank">Beyond Accuracy: A Comprehensive Benchmark of RAG and Multimodal Retrieval Models</a></li>
      <li><a href="https://medium.com/@zc542/from-cloud-to-pocket-a-practical-on-device-llm-benchmark-270b67b855f3" target="_blank">From Cloud to Pocket: A Practical On-Device LLM Benchmark</a></li>
    </ul>
  </div>
</main>

<footer class="footer">
  <div class="container">
    © 2025 Zekai Chen
  </div>
</footer>

</body>
</html>
